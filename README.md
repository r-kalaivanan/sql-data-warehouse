# SQL Data Warehouse

> A modern, enterprise-grade data warehouse built on SQL Server, featuring a medallion architecture (Bronze-Silver-Gold) for ETL processes, dimensional modeling, and business intelligence analytics.

[![SQL Server](https://img.shields.io/badge/SQL%20Server-2019+-CC2927?style=flat&logo=microsoft-sql-server)](https://www.microsoft.com/sql-server)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Architecture](https://img.shields.io/badge/Architecture-Medallion-green.svg)]()

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Features](#features)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Project Structure](#project-structure)
- [Data Flow](#data-flow)
- [Usage](#usage)
- [Documentation](#documentation)
- [Data Governance](#data-governance)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

This project implements a production-ready data warehouse solution that integrates data from multiple source systems (CRM and ERP) to provide a unified view for business intelligence and analytics. The warehouse follows the **Medallion Architecture** pattern with three distinct layers, ensuring data quality, scalability, and performance.

### Key Capabilities

- **Multi-Source Integration**: Combines CRM customer/sales data with ERP operational data
- **Data Quality Framework**: Automated quality checks and data validation at each layer
- **Dimensional Modeling**: Star schema design optimized for analytics and reporting
- **ETL Automation**: Stored procedures for automated data transformation and loading
- **Incremental Processing**: Handles full and incremental data loads efficiently

---

## ğŸ—ï¸ Architecture

The data warehouse implements a **three-tier medallion architecture**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GOLD LAYER                               â”‚
â”‚              (Business-Ready Star Schema)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ dim_customers   â”‚  â”‚  dim_products   â”‚  â”‚   fact_sales    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SILVER LAYER                              â”‚
â”‚              (Cleansed & Standardized)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ CRM Tables   â”‚  â”‚ ERP Tables   â”‚  â”‚ Quality      â”‚          â”‚
â”‚  â”‚ - Customers  â”‚  â”‚ - Demographicsâ”‚ â”‚ Checks       â”‚          â”‚
â”‚  â”‚ - Products   â”‚  â”‚ - Locations  â”‚  â”‚              â”‚          â”‚
â”‚  â”‚ - Sales      â”‚  â”‚ - Categories â”‚  â”‚              â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BRONZE LAYER                              â”‚
â”‚              (Raw Ingestion Zone)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Source System Data (CRM & ERP)                          â”‚   â”‚
â”‚  â”‚  - Raw, unprocessed data                                 â”‚   â”‚
â”‚  â”‚  - Historical point-in-time snapshots                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer Descriptions

#### ğŸ¥‰ Bronze Layer

- **Purpose**: Raw data ingestion from source systems
- **Characteristics**: Minimal transformation, preserves source data as-is
- **Sources**: CRM (customers, products, sales) and ERP (demographics, locations, categories)
- **Schema**: `bronze.crm_*` and `bronze.erp_*` tables

#### ğŸ¥ˆ Silver Layer

- **Purpose**: Data cleansing, standardization, and quality assurance
- **Characteristics**:
  - Deduplication and data type standardization
  - Business rule application
  - Data quality checks and validation
  - Slow-changing dimension (SCD) handling
- **Schema**: `silver.crm_*` and `silver.erp_*` tables

#### ğŸ¥‡ Gold Layer

- **Purpose**: Business-ready dimensional model for analytics
- **Characteristics**:
  - Star schema design (dimensions + facts)
  - Optimized for query performance
  - Aggregated and enriched data
  - Ready for BI tools consumption
- **Schema**: `gold.dim_*` and `gold.fact_*` views

---

## âœ¨ Features

### Data Integration

- âœ… Multi-source data integration (CRM + ERP)
- âœ… Automated ETL pipelines with stored procedures
- âœ… Change data capture and historical tracking
- âœ… Data lineage and transformation documentation

### Data Quality

- âœ… Automated quality checks at each layer
- âœ… Null value handling and default value assignment
- âœ… Data validation rules and constraints
- âœ… Duplicate detection and resolution

### Analytics & Reporting

- âœ… Star schema dimensional model
- âœ… Pre-aggregated metrics for performance
- âœ… Time-series analysis capabilities
- âœ… Customer and product analytics

### Performance & Scalability

- âœ… Optimized query patterns
- âœ… Materialized views for frequently accessed data
- âœ… Incremental loading strategies
- âœ… Partition-ready design

---

## ğŸ“¦ Prerequisites

Before setting up the data warehouse, ensure you have:

- **SQL Server 2019 or later** (Enterprise, Standard, or Developer Edition)
- **SQL Server Management Studio (SSMS)** 18.0 or later
- **Minimum Hardware**:
  - 8 GB RAM (16 GB recommended)
  - 50 GB available disk space
  - Multi-core processor
- **Permissions**:
  - `sysadmin` or `db_creator` role for database creation
  - Ability to execute DDL and DML statements

---

## ğŸš€ Installation

Follow these steps to set up the data warehouse:

### Step 1: Clone the Repository

```bash
git clone https://github.com/your-org/sql-data-warehouse.git
cd sql-data-warehouse
```

### Step 2: Initialize the Database

Run the initialization script to create the database and schemas:

```sql
-- Connect to SQL Server using SSMS or sqlcmd
sqlcmd -S localhost -i scripts/init_data_warehouse.sql
```

This creates:

- `data_warehouse` database
- Three schemas: `bronze`, `silver`, `gold`

### Step 3: Create Bronze Layer Tables

```sql
-- Create CRM tables
sqlcmd -S localhost -d data_warehouse -i scripts/bronze/create_bronze_crm_tables.sql

-- Create ERP tables
sqlcmd -S localhost -d data_warehouse -i scripts/bronze/create_bronze_erp_tables.sql
```

### Step 4: Create Silver Layer Tables

```sql
-- Create CRM silver tables
sqlcmd -S localhost -d data_warehouse -i scripts/silver/create_silver_crm_tables.sql

-- Create ERP silver tables
sqlcmd -S localhost -d data_warehouse -i scripts/silver/create_silver_erp_tables.sql

-- Create ETL stored procedure
sqlcmd -S localhost -d data_warehouse -i scripts/silver/insert_stored_procedure.sql
```

### Step 5: Create Gold Layer Views

```sql
-- Create dimensional model
sqlcmd -S localhost -d data_warehouse -i scripts/gold/ddl_gold.sql
```

### Step 6: Load Sample Data (Optional)

```sql
-- Insert sample data into bronze tables
sqlcmd -S localhost -d data_warehouse -i scripts/bronze/insert_bronze_crm_erp_tables.sql
```

### Step 7: Run ETL Process

```sql
-- Execute the silver layer ETL procedure
USE data_warehouse;
GO
EXEC silver.load_silver;
GO
```

---

## ğŸ“ Project Structure

```
sql-data-warehouse/
â”‚
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ LICENSE                            # License information
â”‚
â”œâ”€â”€ docs/                              # Documentation
â”‚   â”œâ”€â”€ gold_layer_data_catalog.md    # Gold layer data dictionary
â”‚   â”œâ”€â”€ data_model.pdf                # Data model diagrams
â”‚   â”œâ”€â”€ data_flow.pdf                 # Data flow documentation
â”‚   â”œâ”€â”€ high_level_architecture.pdf   # Architecture overview
â”‚   â””â”€â”€ integration_model.pdf         # Integration patterns
â”‚
â”œâ”€â”€ datasets/                          # Sample datasets (optional)
â”‚
â”œâ”€â”€ scripts/                           # SQL scripts
â”‚   â”œâ”€â”€ init_data_warehouse.sql       # Database initialization
â”‚   â”‚
â”‚   â”œâ”€â”€ bronze/                       # Bronze layer scripts
â”‚   â”‚   â”œâ”€â”€ create_bronze_crm_tables.sql
â”‚   â”‚   â”œâ”€â”€ create_bronze_erp_tables.sql
â”‚   â”‚   â””â”€â”€ insert_bronze_crm_erp_tables.sql
â”‚   â”‚
â”‚   â”œâ”€â”€ silver/                       # Silver layer scripts
â”‚   â”‚   â”œâ”€â”€ create_silver_crm_tables.sql
â”‚   â”‚   â”œâ”€â”€ create_silver_erp_tables.sql
â”‚   â”‚   â”œâ”€â”€ insert_stored_procedure.sql
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ crm/                      # CRM transformations
â”‚   â”‚   â”‚   â”œâ”€â”€ cust_info/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ insert_transformed_data.sql
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ quality_check.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ prd_info/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ insert_transformed_data.sql
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ quality_check.sql
â”‚   â”‚   â”‚   â””â”€â”€ sales_details/
â”‚   â”‚   â”‚       â”œâ”€â”€ insert_transformed_data.sql
â”‚   â”‚   â”‚       â””â”€â”€ quality_check.sql
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ erp/                      # ERP transformations
â”‚   â”‚       â”œâ”€â”€ cust_az12/
â”‚   â”‚       â”‚   â”œâ”€â”€ insert_transformed_data.sql
â”‚   â”‚       â”‚   â””â”€â”€ quality_check.sql
â”‚   â”‚       â”œâ”€â”€ loc_a101/
â”‚   â”‚       â”‚   â”œâ”€â”€ insert_transformed_data.sql
â”‚   â”‚       â”‚   â””â”€â”€ quality_check.sql
â”‚   â”‚       â””â”€â”€ px_cat_g1v2/
â”‚   â”‚           â”œâ”€â”€ insert_transformed_data.sql
â”‚   â”‚           â””â”€â”€ quality_check.sql
â”‚   â”‚
â”‚   â””â”€â”€ gold/                         # Gold layer scripts
â”‚       â””â”€â”€ ddl_gold.sql              # Dimensional model views
â”‚
â””â”€â”€ tests/                            # Test scripts
```

---

## ğŸ”„ Data Flow

### End-to-End Pipeline

```
1. Source Systems (CRM & ERP)
   â”‚
   â”œâ”€â†’ Data Extraction
   â”‚
2. Bronze Layer (Raw Ingestion)
   â”‚
   â”œâ”€â†’ Data Cleansing & Standardization
   â”‚   - Remove duplicates
   â”‚   - Standardize data types
   â”‚   - Apply business rules
   â”‚
3. Silver Layer (Quality & Transformation)
   â”‚
   â”œâ”€â†’ Data Integration & Enrichment
   â”‚   - Join CRM and ERP data
   â”‚   - Create surrogate keys
   â”‚   - Build dimensions and facts
   â”‚
4. Gold Layer (Star Schema)
   â”‚
   â””â”€â†’ BI Tools & Analytics
       - Power BI
       - Tableau
       - Custom Reports
```

### ETL Process

The `silver.load_silver` stored procedure orchestrates the entire ETL pipeline:

1. **Truncate Silver Tables**: Clears existing data for full refresh
2. **Transform CRM Data**:
   - Customer information (deduplication, standardization)
   - Product information (category parsing, null handling)
   - Sales details (date conversion, data validation)
3. **Transform ERP Data**:
   - Customer demographics
   - Location data
   - Product categories
4. **Data Quality Checks**: Validates transformed data
5. **Logging**: Records execution time and row counts

---

## ğŸ’» Usage

### Querying the Data Warehouse

#### Example 1: Customer Sales Summary

```sql
SELECT
    dc.first_name,
    dc.last_name,
    dc.country,
    SUM(fs.sales_amount) AS total_sales,
    COUNT(DISTINCT fs.order_number) AS order_count
FROM gold.fact_sales fs
INNER JOIN gold.dim_customers dc ON fs.customer_key = dc.customer_key
GROUP BY dc.first_name, dc.last_name, dc.country
ORDER BY total_sales DESC;
```

#### Example 2: Product Performance by Category

```sql
SELECT
    dp.category,
    dp.subcategory,
    SUM(fs.sales_amount) AS total_revenue,
    SUM(fs.quantity) AS units_sold,
    AVG(fs.price) AS avg_price
FROM gold.fact_sales fs
INNER JOIN gold.dim_products dp ON fs.product_key = dp.product_key
GROUP BY dp.category, dp.subcategory
ORDER BY total_revenue DESC;
```

#### Example 3: Monthly Sales Trend

```sql
SELECT
    YEAR(fs.order_date) AS year,
    MONTH(fs.order_date) AS month,
    SUM(fs.sales_amount) AS monthly_sales,
    COUNT(DISTINCT fs.customer_key) AS unique_customers
FROM gold.fact_sales fs
GROUP BY YEAR(fs.order_date), MONTH(fs.order_date)
ORDER BY year, month;
```

### Running Quality Checks

Execute quality check scripts to validate data integrity:

```sql
-- Check customer data quality
:r scripts/silver/crm/cust_info/quality_check.sql

-- Check product data quality
:r scripts/silver/crm/prd_info/quality_check.sql

-- Check sales data quality
:r scripts/silver/crm/sales_details/quality_check.sql
```

### Refreshing the Data Warehouse

To refresh all silver layer data from bronze:

```sql
USE data_warehouse;
GO

-- Execute ETL procedure
EXEC silver.load_silver;
GO

-- Verify gold layer views
SELECT COUNT(*) FROM gold.dim_customers;
SELECT COUNT(*) FROM gold.dim_products;
SELECT COUNT(*) FROM gold.fact_sales;
```

---

## ğŸ“š Documentation

Comprehensive documentation is available in the `docs/` folder:

- **[Gold Layer Data Catalog](docs/gold_layer_data_catalog.md)**: Complete data dictionary for all gold layer objects, including column specifications, data lineage, and usage examples

- **Data Model**: Entity-relationship diagrams and star schema design

- **Data Flow**: Visual representation of data movement through layers

- **High Level Architecture**: System architecture and component interactions

- **Integration Model**: Source system integration patterns

---

## ğŸ›¡ï¸ Data Governance

### Data Quality Standards

- **Completeness**: All required fields must be populated
- **Accuracy**: Data validated against business rules
- **Consistency**: Standardized formats across sources
- **Timeliness**: Regular refresh schedule maintained

### Access Control

```sql
-- Grant read access to analysts
GRANT SELECT ON SCHEMA::gold TO analyst_role;

-- Grant ETL execution permissions
GRANT EXECUTE ON silver.load_silver TO etl_service_account;

-- Restrict bronze layer access
DENY SELECT ON SCHEMA::bronze TO analyst_role;
```

### Data Retention

- **Bronze Layer**: 90 days rolling retention
- **Silver Layer**: 2 years historical data
- **Gold Layer**: Full historical archive

---

## ğŸ¤ Contributing

We welcome contributions! Please follow these guidelines:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/your-feature-name`
3. **Make your changes**: Follow SQL best practices and naming conventions
4. **Test thoroughly**: Validate all scripts before committing
5. **Document changes**: Update relevant documentation
6. **Submit a pull request**: Provide clear description of changes

### Coding Standards

- Use consistent indentation (4 spaces)
- Include comments for complex logic
- Follow naming conventions:
  - Tables: `schema_sourcesystem_tablename`
  - Views: `dim_*` or `fact_*`
  - Procedures: `verb_noun` (e.g., `load_silver`)
- Always include error handling in stored procedures

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ“ Contact & Support

For questions, issues, or suggestions:

- **Email**: data-engineering@company.com
- **Issue Tracker**: [GitHub Issues](https://github.com/your-org/sql-data-warehouse/issues)
- **Documentation**: [Project Wiki](https://github.com/your-org/sql-data-warehouse/wiki)

---

## ğŸ™ Acknowledgments

Built with best practices from:

- Kimball Dimensional Modeling techniques
- Databricks Medallion Architecture pattern
- Microsoft SQL Server best practices

---

**Version**: 1.0.0  
**Last Updated**: February 25, 2026  
**Maintained by**: Data Engineering Team
